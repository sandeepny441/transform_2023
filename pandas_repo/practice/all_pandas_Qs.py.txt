

import pandas as pd
data = {}

data['A'] = list(range(10))
data['B'] = list(range(10, 20))
data['C'] = list(range(20, 30))

df1 = pd.DataFrame(data)
df1.head()


# 1- LOC questions 

Basic Indexing: How would you use loc to get all the values in the row where the index is 2? 
 
Multiple Columns: How would you use loc to retrieve the values in columns 'A' and 'C' for the rows with indices 1 and 3? 
 
Conditional Filtering: How can you use loc to filter rows where the values in column 'B' are greater than or equal to 13 and only show column 'A' for those rows? 
 
Row and Column Together: How would you use loc to get the value located in the row with index 4 and column 'B'? 
 
Modify Values: How would you use loc to change the value in the row where the index is 0 and the column is 'C' to 99?

Range of Rows: How would you use loc to select all rows from index 2 to 5, inclusive, and only columns 'A' and 'B'?

Boolean Conditions with Multiple Columns: How can you use loc to filter rows where column 'A' is greater than 10 and column 'B' is less than 20, and then only retrieve these rows for columns 'A' and 'C'?

Modify Multiple Values: How would you use loc to change all values in column 'D' to 0 where column 'B' is less than 5?

Slice Columns: How can you use loc to select all rows and columns from 'B' to 'D'?

Modify Row Values: How would you use loc to update all the column values in a row with index 3 to a new list of values [10, 20, 30, 40]?

Negate Conditions: How would you use loc to select all rows where column 'A' is not equal to 10 and then only retrieve the values for columns 'C' and 'D'?

Multiple Conditions for Rows and Columns: How would you use loc to select rows where column 'A' is greater than 5 and column 'B' is not equal to 7, and then retrieve columns 'A', 'C', and 'E'?

Set Values Based on Another Column: How would you use loc to set the values in column 'D' to be the same as the values in column 'B' for rows where column 'A' is greater than 10?

Partial String Matching: If column 'E' contains string values, how would you use loc to filter rows where the values in column 'E' start with the letter 'S', and retrieve only column 'A' for those rows?

Using Functions in Conditions: How would you use loc to filter rows based on a custom function applied to one of the columns, and then retrieve specific columns for those rows?

======================================================================================================
======================================================================================================

# 2- iloc 15 Questions
How would you use .iloc to get the first row of the DataFrame?

How would you use .iloc to get the last row of the DataFrame?

How would you use .iloc to get the first 3 rows and the first 2 columns?

How would you use .iloc to get the last 2 rows and last 2 columns?

How would you use .iloc to get all the rows but only the first column?

How would you use .iloc to get all the columns but only the third row?

How would you use .iloc to get rows from index 4 to index 6, inclusive, and only the second column?

How would you use .iloc to get the value at the fifth row and third column?

How would you use .iloc to get all rows for columns at index 0 and index 2?

How would you use .iloc to update the value at the first row and first column to 99?

How would you use .iloc to set all values in the last column to 0?

How would you use .iloc to swap the first and last rows?

How would you use .iloc to reverse the order of rows?

How would you use .iloc to get rows where the index is even and only the first column?

How would you use .iloc to get rows from index 2 to index 8 but only for columns at index 1 and index 2?

======================================================================================================
======================================================================================================

#Count Questions
import pandas as pd

# Create a dictionary containing your data
data = {
    'worker_id': [1, 2, 3, 4, 5],
    'first_name': ['Monika', 'Niharika', 'Vishal', 'Amitah', 'Vivek'],
    'last_name': ['Arora', 'Verma', 'Singhal', 'Singh', 'Bhati'],
    'salary': [100000, 80000, 300000, 500000, 500000],
    'joining_date': ['2014-02-20 00:00:00', '2014-06-11 00:00:00', '2014-02-20 00:00:00', '2014-02-20 00:00:00', '2014-06-11 00:00:00'],
    'department': ['HR', 'Admin', 'HR', 'Admin', 'Admin']
}

# Create DataFrame
df = pd.DataFrame(data)


How would you use count to find the total number of rows in the DataFrame?

How can you use count to find the number of non-NA/null entries in the 'salary' column?

How would you apply count to find the number of non-NA/null entries for each column in the DataFrame?

Can you use count along with groupby to find out how many workers are in each department?

How can you use count to find out how many unique 'joining_date' values are present in the DataFrame?

How would you use count to determine the number of workers who have a salary greater than 100,000?

Is it possible to use count to find the number of workers with the last name 'Singh'? How would you do it?

Can you apply count to find the number of rows where both 'first_name' and 'last_name' are non-NA/null?

How would you use count to find the number of workers who joined before a certain date, for example, '2014-05-01'?

Can you use count and query together to find the number of 'HR' department workers with a salary greater than 100,000?

How can you use count along with loc to find the number of entries in the 'first_name' column for the department 'Admin'?

How would you use count to find the number of workers who have 'last_name' with more than 5 characters?

Can you use count to find the number of rows where the 'worker_id' is an even number?

How would you use count to find the number of workers whose 'first_name' starts with the letter 'V'?

How would you use count to determine how many workers have both 'first_name' and 'last_name' that are exactly 6 characters long?

======================================================================================================
======================================================================================================

# size Questions 

import pandas as pd
from datetime import datetime

# Sample data
data = {
    'Order_ID': [1, 2, 3, 4, 5],
    'Customer_ID': [101, 102, 103, 104, 105],
    'Restaurant_ID': [201, 202, 203, 204, 205],
    'Order_Date': [datetime(2023, 8, 1), datetime(2023, 8, 2), datetime(2023, 8, 3), datetime(2023, 8, 4), datetime(2023, 8, 5)],
    'Order_Time': ['12:30:00', '18:45:00', '19:20:00', '13:15:00', '09:30:00'],
    'Food_Item': ['Burger', 'Sushi', 'Pasta', 'Pizza', 'Salad'],
    'Quantity': [2, 1, 3, 1, 1],
    'Price': [12.99, 18.50, 10.99, 14.99, 7.99],
    'Delivery_Time(min)': [30, 45, 40, 35, 25],
    'Rating': [4.5, 4.0, 5.0, 3.5, 4.0]
}

# Create DataFrame
uber_eats_df = pd.DataFrame(data)

What will the size attribute return when applied to the uber_eats_df DataFrame?

How would you verify if the size attribute counts the number of rows, columns, or individual elements in the DataFrame?

If you apply a filter to uber_eats_df to only include rows where Rating is greater than or equal to 4.5, what will the size attribute return for the filtered DataFrame?

Compare the output of uber_eats_df.size and uber_eats_df.shape. What mathematical operation could you apply to the values in shape to derive the value of size?

If you select only the 'Food_Item' and 'Price' columns from uber_eats_df, what will be the output of the size attribute?

How would the size attribute change if you dropped a row from uber_eats_df? Can you confirm this by coding it?

Create a Series object by selecting the Price column from uber_eats_df. What does the size attribute show for this Series object?

Does the size attribute include NaN values if they were present in the DataFrame? (You might want to modify the DataFrame to include a NaN value to answer this question.)

How would the output of uber_eats_df.size change if you added a new column to the DataFrame? Can you confirm your answer by coding it?

#========================================================================================
#========================================================================================
#NULLs

import pandas as pd
import numpy as np

# Sample DataFrame
data = {
    'Product_ID': [1, 2, 3, 4, 5, np.nan],
    'Product_Name': ['Laptop', 'Phone', 'TV', 'Headphones', None, 'Microwave'],
    'Stock': [20, 15, np.nan, 30, 25, 12],
    'Price': [999.99, 799.99, 399.99, np.nan, 59.99, 99.99],
    'Discounted': [True, False, True, False, np.nan, True],
}

target_df = pd.DataFrame(data)

NULLs 

Identify Null values
How would you identify rows where the 'Stock' column has null values in the provided target_df DataFrame?
Can you list the columns in target_df that contain at least one null value?
How would you use pd.isna() to identify null values in the entire target_df DataFrame?
If you wanted to identify rows where both 'Stock' and 'Price' have null values, how would you do it?

Filtering
How would you filter out rows where the 'Stock' column has null values in the target_df DataFrame?
What method would you use to remove any row that has at least one null value in target_df?
If you only want to drop rows where both 'Stock' and 'Price' have null values, how would you go about doing this in target_df?

Filling 
How would you fill null values in the 'Stock' column with the median value of that column?
Can you use the .fillna() method to fill null values in multiple columns ('Stock' and 'Price') at once? If so, how?
If you only want to fill the first null value in each column with a zero, how would you do it?


Counting 
How would you count the number of null values in the entire DataFrame?
Is there a way to get a count of non-null values for each column in the DataFrame?
How would you count null values in a specific row, say the row at index 2?


Replacing 
If you wanted to replace all null values in the DataFrame with the string "Unknown", how would you do it?
Can you replace null values in one column ('Stock') with zero and in another column ('Discounted') with False, all in a single line of code?
How would you replace all instances of a specific value, let's say 999.99 in the 'Price' column, with np.nan?


Operations 
How would you calculate the sum of each column in target_df, considering that some columns might have null values?
If you have null values in the 'Stock' and 'Price' columns, and you attempt to multiply these columns element-wise, what will happen to the resulting product where null values are involved?
How would you use the dropna method to perform an operation, say calculating the mean, only on non-null elements in the 'Stock' column?


Propagating
How would you propagate the last valid observation in the 'Stock' column to fill NaN values?
Can you propagate the next valid observation backward to fill NaN values in the 'Price' column? If so, how would you do it?
How would you limit the number of NaN values filled by forward fill (or backward fill) to 1 in the 'Stock' column?

# unqiue and n-unique
import pandas as pd

# Sample data
data = {
    'Product_ID': [1, 2, 3, 4, 5, 6, 1, 2, 3, 4],
    'Product_Name': ['Toothpaste', 'Shampoo', 'Laptop', 'TV', 'Coffee Maker', 'Blender', 'Toothpaste', 'Shampoo', 'Laptop', 'TV'],
    'Category': ['Personal Care', 'Personal Care', 'Electronics', 'Electronics', 'Kitchen Appliances', 'Kitchen Appliances', 'Personal Care', 'Personal Care', 'Electronics', 'Electronics'],
    'Price': [5.0, 10.0, 1000.0, 600.0, 50.0, 30.0, 5.0, 10.0, 1000.0, 600.0],
    'Units_Sold': [100, 50, 20, 15, 30, 25, 110, 55, 22, 17]
}

target_df = pd.DataFrame(data)

#UNIQUE
How many unique Product_IDs are there in the DataFrame?
What are the unique product categories available in the DataFrame?
How many different price points are in the DataFrame?
Are there any products that were sold in different units (check for unique 'Units_Sold')?
How many unique combinations of 'Product_ID' and 'Price' are there?
Are all 'Units_Sold' for 'Toothpaste' the same or are there unique values?

#N_UNIQUE
How many unique categories of products does the Target store offer? Use nunique() to find out.
How many different unique price points exist for 'Electronics' in the DataFrame? Use nunique() to get the answer.
Are the units in which products sold always unique, or do some products share the same number of 'Units_Sold'? Use nunique() to determine this.
How many unique 'Product_ID' are there for products in the 'Personal Care' category? Utilize nunique() for this.

# duplicate
How would you identify if there are any duplicate rows in the DataFrame? What function would you use?
If the DataFrame has a column for 'Product_ID', how would you find out if there are any duplicate 'Product_ID' entries?
How would you remove duplicate rows in the DataFrame? Which function can accomplish this?
If the DataFrame has columns 'Product_ID' and 'Product_Category', how would you remove rows where only 'Product_ID' is duplicated but keep the first occurrence?
Is it possible to keep the last occurrence of a duplicate 'Product_ID' and remove the rest? If so, how would you do it?

#drop_duplicates
How would you use the drop_duplicates function to remove all rows that have identical values across all columns?
If your DataFrame contains columns 'Product_ID', 'Product_Name', and 'Price', how would you use drop_duplicates to keep only the unique 'Product_ID' rows, while retaining the first occurrence of each 'Product_ID'?
Is it possible to use drop_duplicates to remove duplicates based on multiple columns, say 'Product_ID' and 'Price'? If so, how would you do it?
How would you use drop_duplicates to keep the last occurrence of each duplicate row based on 'Product_ID' and remove the earlier ones?
Can you specify whether to keep or drop duplicates in place, without creating a new DataFrame? If so, what parameter would you use?

# SORT_Questions
import pandas as pd

# Sample data
data = {
    'Player': ['Roger Federer', 'Rafael Nadal', 'Novak Djokovic', 'Serena Williams', 'Margaret Court', 'Arthur Ashe', 'Andre Agassi', 'Pete Sampras', 'Martina Navratilova', 'Chris Evert', 'Steffi Graf', 'Rod Laver'],
    'Total_Slams': [20, 20, 20, 23, 24, 3, 8, 14, 18, 18, 22, 11],
    'Wimbledon': [8, 2, 6, 7, 3, 1, 1, 7, 9, 3, 7, 4],
    'US_Open': [5, 4, 3, 6, 5, 1, 2, 5, 4, 6, 5, 2],
    'Australian_Open': [6, 1, 9, 7, 11, 1, 4, 2, 3, 2, 4, 3],
    'French_Open': [1, 13, 2, 3, 5, 0, 1, 0, 2, 7, 6, 2],
}

tennis_df = pd.DataFrame(data)

How would you sort the DataFrame based on the "Total_Slams" column in descending order?

Can you sort the DataFrame by the players' names in alphabetical order? What method would you use?

Is it possible to sort the DataFrame based on multiple columns? For instance, sort by "Total_Slams" first and then by "Wimbledon" titles.

How would you sort the DataFrame based on the "French_Open" column but keep the original index?

Can you perform an in-place sort on the "US_Open" titles, so the original DataFrame is modified?

What is the syntax for sorting the DataFrame based on "Australian_Open" in ascending order but returning only a subset of the DataFrame instead of modifying it?

How would you reset the index after sorting the DataFrame based on "Total_Slams"?

Is it possible to sort just a Series extracted from the DataFrame? For example, sort the "Wimbledon" Series.

How can you sort the DataFrame by the index after you've sorted it by a column?

Can you sort the DataFrame by "Total_Slams" in descending order but display only the top 5 players?












